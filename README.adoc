= CUA Hub
:toc: left
:toc-title: Table des matières
:sectnums:
:icons: font

Le CUA Hub construit et expose le catalogue unifié des applications sur la base de catalogues source.

Il s'agit d'une application Spring Boot 2 au format WAR, déployable donc sur serveur compatible avec la spécification Servlet 3.1.

*Référence :* https://ipanema.education.fr/xwiki/bin/view/Main/Catalogue%20Unifi%C3%A9%20des%20Applications/[Espace Wiki pour le projet CUA]

== Fonctionnement

Le CUA Hub permet à ses clients d'accéder facilement à la liste des applications associées à un utilisateur.
Ces applications sont gérées au sein de services existants (désignés comme "catalogues source").
Le CUA Hub se sert de bases de données CouchDB pour stocker les listes d'applications (faisant office de cache) ainsi que les données complémentaires utilisées pour les fonctionnalités spécifiques : gestion de l'ordre et mise en favori.

.Contexte d'exécution du CUA Hub
[plantuml,diag-contexte,svg,align="center"]
----
@startuml
interface "API CUA"
component "CUA Hub"
interface "API consumer Toutatice"
interface "API consumer GAR"
interface "API consumer ARENA"
database CouchDB

[API CUA] -- [CUA Hub]
[CUA Hub] - [CouchDB]
[CUA Hub] --> [API consumer Toutatice]
[CUA Hub] --> [API consumer GAR]
[CUA Hub] --> [API consumer ARENA]
@enduml
----

La synchronisation du catalogue unifié avec les catalogues source se fait à l'initiative de ses clients.
Les catalogues source sont exposés à travers des composants "consumer" faisant partie de l'écosystème CUA.

== Architecture

.Vue d'ensemble de l'architecture interne du CUA Hub
[plantuml,diag-archi,svg,align="center"]
----
@startuml
component "CUA Hub" {
    package config
    package rest
    package catalogue
    package storage
    package log
    package source {
        package toutatice
        package gar
        package arena
    }

    rest -- catalogue
    catalogue - storage
    catalogue -- gar
    catalogue -- toutatice
    catalogue -- arena
}
component "CUA data"

[CUA Hub] --> [CUA data]
@enduml
----

L'architecture interne de l'application est organisée de telle sorte à pouvoir facilement s'y retrouver, chaque _package_ ayant une responsabilité claire :

* `catalogue` : cœur métier de l'application
* `rest` : tout ce qui est spécifique à l'API REST
* `storage` : tout ce qui est spécifique au stockage des données
* `source` : tout ce qui est spécifique aux catalogues sources
* `config` : configuration globale de l'application
* `log` : loggers permettant de garantir les formats décris plus loin dans le présent document

=== Choix techniques particuliers

==== Versionnement de l'API

Les URL utilisées par l'API contiennent un numéro de version (`v1`).
Si l'API s'avère suffisamment stable pour ne pas nécessiter de modifications incompatibles dans le futur, cela est peu utile.

Dans le cas contraire néanmoins, cela peut nous permettre d'aménager une période de transition pendant laquelle on pourra conserver l'ancien fonctionnement en plus du nouveau, le temps que l'ensemble des clients soit mis à jour.

==== Gestion des bases CouchDB

Nous utilisons le module "couch_peruser", qui crée automatiquement pour chaque utilisateur CouchDB une base de données associée, à laquelle seule cet utilisateur et l'administrateur ont accès.
Nous considérons que l'identifiant utilisateur CouchDB est l'identifiant du catalogue au sein de l'application.
(En situation de production, nous nous attendons à ce que cet identifiant soit identique à l'identifiant de l'utilisateur associé.)

Le CUA Hub se charge de créer les catalogues au moment de la première demande de synchronisation par un client.
Le mot de passe associé au compte utilisateur est identique à l'identifiant.
Comme le CUA Hub se connecte à CouchDB avec le compte administrateur dans tous les cas, cette information n'est pas utilisée à l'heure actuelle.

Quand il sera permis à un client d'accéder directement à CouchDB (pour une synchronisation PouchDB par exemple), il faudra prévoir un mécanisme non basé sur une valeur aussi triviale.

== Développementajouter l'extension ADOC sur intelligJ

Le projet est géré à l'aide de Maven, dont les commandes de base peuvent être utilisées.

=== Construction du livrable

Construction du fichier WAR sur base propre :

    mvn clean package

Les profils suivants sont définis :

* `dev` : active le profil Spring `dev`, utile uniquement en cas d'exécution locale
* `mutation` : active l'exécution de tests mutés, pour analyser plus finement l'utilité des tests automatiques (peut prendre quelques minutes, inactif par défaut)
* `securite` : active l'analyse des dépendances orientée sécurité (peut prendre quelques minutes, inactif par défaut)

Les rapports suivants sont produits au cours de la construction :

* `target/site/jacoco/index.html` : couverture du code par les tests automatiques
* `target/pit-reports/{dateExecution}/index.html` : lignes de code non testées détectées par mutation (créé uniquement si le profil `mutation` a été activé)

=== Exécution locale

Pour lancer l'application en local, vous devez disposer d'une instance CouchDB ainsi qu'un accès à des services exposant la même API que les consumers correspondant aux catalogues source.

==== Exécution avec Docker

Des fichiers `Dockerfile` existent dans le projet pour construire les conteneurs suivants :

* Un conteneur lançant le CUA Hub construit par la commande précédente, décrit par le fichier à la racine du projet
* Un conteneur lançant un bouchon simulant les consumers GAR et Toutatice, décrit par les fichiers situés dans `src/main/bouchon` ; à noter que ce bouchon simule des ajout et suppression d'applications dans les catalogues source toutes les 3 sollicitations

En plus, un fichier `docker-compose.yml` a été aussi créé à la racine du projet afin de décrire une infrastructure exploitant ces conteneurs, ainsi que la création d'un conteneur CouchDB.
Ainsi, à partir du moment où Docker et Docker Compose sont installés, il est possible de lancer un environnement complet avec la commande suivante :

    docker-compose up -d

Pour faciliter l'installation de Docker et Docker Compose sur un poste Ubuntu, il est possible de lancer le script `src/main/docker/install_docker.ubuntu.sh` qui se charge de tout.

.Environnement de démonstration pour CUA Hub créé par Docker Compose
[plantuml,diag-contexte,svg,align="center"]
----
@startuml
[ihm] --> [hub]
[hub] -> [couchdb]
[hub] --> [consumers]
@enduml
----

[IMPORTANT]
====
Le conteneur "ihm" n'existe pas à l'heure actuelle, mais devrait être rajouté sous peu.
====

[NOTE]
====
La commande `docker-compose` lance les conteneurs en mode "détaché", c'est-à-dire qu'elle rend la main plutôt que d'afficher les logs de tous les conteneurs pendant qu'ils tournent.
On peut consulter la liste des conteneurs en cours d'exécution pour le projet courant avec la commande `docker container ls`.
Pour consulter les logs produits par un des conteneurs, on utilise la commande `docker container logs <nom_ou_identifiant>` (ajouter `--follow` en fin de commande pour suivre l'évolution des logs en direct).

On peut arrêter et supprimer les conteneurs avec la commande `docker-compose down`.
Les données CouchDB sont conservées dans des volumes Docker (que l'on peut lister avec `docker volume ls`).
Par conséquent, tant que ces volumes ne sont pas supprimés, lancer `docker-compose up` par la suite permet de retrouver les données présentes dans CouchDB.

Se référer à la https://docs.docker.com/[documentation de Docker et Docker Compose] pour plus d'informations.
====

==== Exécution sans Docker

L'utilisation de Docker n'est pas obligatoire, à condition de disposer d'une instance CouchDB locale et de pouvoir accéder à partir de sa machine à http://qt.toutatice.fr.
Dans ce cas, CUA Hub fonctionnera avec les _consumers_ déployés sur QT quand on le lance avec la commande suivante :

    mvn

Au besoin, il est possible de démarrer les bouchons utilisés avec Docker en local, en suivant les instructions suivantes (NodeJS doit être installé) :

* Copier le contenu du dossier `src/main/bouchon` en-dehors du projet (car l'opération suivante va copier des fichiers qui _ne doivent pas_ être versionnés)
* Dans le dossier nouvellement créé, lancer la commande `npm install --production` pour récupérer les dépendances utilisées par le bouchon
* Entrer dans le dossier `app` et lancer le serveur avec la commande `node index.js`
* Modifier le fichier de configuration `src/main/resources/application-dev.yml` et y remplacer `qt.toutatice.fr` par `localhost:3000`
* Relancer le CUA Hub avec la commande `mvn`

==== Initialisation au premier lancement

Une fois CouchDB lancé, vous pouvez accéder à sa console d'administration via l'adresse http://localhost:5984/_utils/.
Le compte administrateur est configuré via les variables d'environnement décrites dans le fichier `docker-compose.yml`.
Accédez à la page d'initialisation de l'instance ("Setup", icône clef à molette) et suivez les instruction pour une "single instance".

Il faut ensuite activer le module "couch_peruser", qui permet la création automatique d'une base dédiée protégée pour chaque nouvel utilisateur.
À cette fin, il faut se rendre sur la page de configuration (icône roue crantée) et passer à `true` les propriétés `couch_peruser.enable` et `couch_peruser.delete_dbs`.

Une foir cette opération effectuée, le CUA Hub peut être utilisé.

Demander une synchronisation avec l'API `/sync` sur un catalogue déclenche la création du compte utilisateur CouchDB et sa base de données associée, si le catalogue n'existait pas auparavant.

=== Création d'une branche

On préconise l'utilisation du plugin Maven Release, qui met automatiquement à jour les informations SCM présentes dans le POM.

La commande à utiliser (mode interactif) est :

    mvn release:branch -DbranchName=NOM_DE_LA_BRANCHE

== Livraison

On préconise l'utilisation du plugin Maven Release pour la livraison d'une version.
Les commandes à utiliser (mode interactif) sont :

    mvn release:prepare
    mvn release:perform

Les propriétés suivantes doivent être définies (idéalement au sein du fichier `settings.xml`) pour que l'opération fonctionne :

* `releaseRepoId` : identifiant du dépôt de binaires
* `releaseRepoUrl` : URL du dépôt de binaires

== Configuration

Les valeurs par défaut sont placées dans les classes dont le nom termine par `Config` définies au sein de l'application.

=== Connexion au service CouchDB

* `cua.hub.couchdb.admin.username` : nom du compte administrateur
** Pas de valeur par défaut, obligatoire
* `cua.hub.couchdb.admin.password` : mot de passe administrateur
** Pas de valeur par défaut, obligatoire
* `cua.hub.couchdb.createdb.attempts` : nombre de vérifications avant de retourner une erreur au client en l'absence d'une base après création du compte CouchDB associé
** Valeur par défaut : `6`
* `cua.hub.couchdb.createdb.wait` : temps d'attente en millisecondes entre la création d'un compte CouchDB et la vérification de l'existence de la base associée, et entre deux vérifications
** Valeur par défaut : `150`
* `cua.hub.couchdb.url` : URL de base du service CouchDB
** Pas de valeur par défaut, obligatoire
* `cua.hub.couchdb.userdb.prefix` : préfixe utilisé pour les bases de données créées pour les catalogues
** Valeur par défaut : `userdb-`

=== Configuration de la synchronisation avec les consumers

* `cua.hub.sync.poolsize` : nombre de synchronisations pouvant être faites de manière simultanée
** Valeur par défaut : `1`
* `cua.hub.sync.mindelay` : durée minimale permise entre deux synchronisations réussies
** Valeur par défaut : `600`
* `cua.hub.consumers.{id}.*` : espace de configuration spécifique pour le consumer `{id}` (voir sections suivantes)

==== Configuration liée au consumer Toutatice

* `cua.hub.consumers.toutatice.active` : activation du lien avec le consumer Toutatice
** Valeur par défaut : `true`
* `cua.hub.consumers.toutatice.url` : URL du consumer Toutatice exposant les applications de ce service
** Pas de valeur par défaut, obligatoire si le lien avec le consumer est actif
* `cua.hub.consumers.toutatice.timeout` : valeur en millisecondes utilisée pour configurer le temps d'attente maximal lors des échanges avec le consumer Toutatice
** Valeur par défaut : `1000`

==== Configuration liée au consumer GAR

* `cua.hub.consumers.gar.active` : activation du lien avec le consumer GAR
** Valeur par défaut : `true`
* `cua.hub.consumers.gar.url` : URL du consumer GAR exposant les applications de ce service
** Pas de valeur par défaut, obligatoire si le lien avec le consumer est actif
* `cua.hub.consumers.gar.timeout` : valeur en millisecondes utilisée pour configurer le temps d'attente maximal lors des échanges avec le consumer Toutatice
** Valeur par défaut : `1000`

== Déploiement

Le déploiement prévu pour l'application utilise un serveur Tomcat existant.

=== Installation du livrable WAR

Le déploiement consiste à placer le livrable WAR dans le dossier `webapps` du serveur Tomcat.
Il y sera automatiquement déployé.

[IMPORTANT]
====
Le nom du fichier (sans extension) sera utilisé dans l'URL exposée par Tomcat.
Il ne faut donc pas que le numéro de version y apparaîsse.
On préconise de nommer le fichier `cua-hub.war`.
On peut utiliser un lien symbolique, si l'on souhaite conserver le nom complet du livrable (avec numéro de version).
====

=== Mise en place de la configuration

Comme il s'agit d'une application Spring Boot, les paramètres de configuration peuvent provenir d'un grand nombre d'emplacements.
Dans un cadre Tomcat, l'application peut être configurée à travers la définition des propriétés directement au sein du fichier de contexte Tomcat (`$TOMCAT_HOME/conf/Catalina/localhost/cua-hub.xml`).
C'est ce que nous préconisons.

[CAUTION]
====
Le fichier de contexte Tomcat doit avoir le même nom que le livrable déployé (hors extension).
Lors de la suppression du WAR déployé, Tomcat supprimera automatiquement le fichier de contexte.
On conseille de le définir ailleurs et d'utiliser un lien symbolique pour ne pas perdre son contenu.
====

== Exploitation

=== Format des logs

Les types de messages de logs suivants sont utilisés :

* `CUA.Hub.Configuration` : paramètres de configuration et leurs valeurs
** `C01` - Valeur configurée
** `F01` - Configuration invalide, le service ne peut pas démarrer
* `CUA.Hub.Performance` : mesures de performances
** `P01` - Durée de traitement d'une requête client API
** `P02` - Durée d'attente d'une opération de synchronisation
** `P03` - Durée de traitement d'une opération de synchronisation
** `P04` - Temps de réponse mesuré lors du requêtage d'un _consumer_
** `P05` - Temps de réponse mesuré lors du requêtage de CouchDB
* `CUA.Hub.API` : messages liés aux sollicitations de l'API
** `I01` - Réception d'une requête sur l'API
** `W01` - Réponse en erreur (dû à une requête invalide)
** `E01` - Réponse en erreur (dû à une erreur du service)
* `CUA.Hub.Synchronisation` : messages liés aux opérations de synchronisation
** `D01` - Requêtage d'un _consumer_
** `E02` - Réponse d'un _consumer_ en erreur (erreur côté _consumer_)
** `E03` - Timeout lors du requêtage d'un _consumer_
** `E04` - Réponse d'un _consumer_ en erreur (dû à une requête invalide)
** `D02` - Changement d'état pour une opération de synchronisation
** `I02` - Synchronisation réussie
** `W04` - Synchronisation échouée
* `CUA.Hub.Persistance` : messages associés aux opérations de persistence CouchDB
** `D03` - Requêtage de CouchDB
** `E05` - Erreur lors des échanges avec CouchDB

Chaque requête reçue se voit associée un identifiant de corrélation.
Cet identifiant apparaît dans les messages de log associés.
Cela nous permettra de facilement filtrer les logs pour n'observer que les messages liés à une requête donnée.
Dans le cas des opérations de synchronisation, cet identifiant est conservé pour le suivi de la synchronisation (alors qu'une réponse a été renvoyée au client).

==== C01 - Valeur configurée

Format : `C01 %{nom} %{valeur}`

Exemples :

    C01 cua.hub.sync.pool.size 4
    C01 cua.hub.consumers.toutatice.url true

==== F01 - Configuration invalide, le service ne peut pas démarrer

Format : `F01 %{message}`

Exemple :

    F01 Valeur manquante pour la propriété cua.hub.consumers.toutatice.url (obligatoire quand cua.hub.consumers.toutatice.active = true)

==== P01 - Durée de traitement d'une requête client API

Format : `P01 %{idCorrelation} Traitement requete %{durée} ms`

Exemple :

    P01 54e160f Traitement requete 57 ms

==== P02 - Durée d'attente d'une opération de synchronisation

Format : `P02 %{idCorrelation} Attente synchronisation %{durée} ms`

Exemple :

    P02 54e160f Attente synchronisation 1453 ms

==== P03 - Durée de traitement d'une opération de synchronisation

Format : `P03 %{idCorrelation} Traitement synchronisation %{durée} ms`

Exemple :

    P03 54e160f Traitement synchronisation 540 ms

==== P04 - Temps de réponse mesuré lors du requêtage d'un _consumer_

Format : `P04 %{idCorrelation} Requetage %{idConsumer} %{durée} ms

Exemples :

    P04 54e160f Requetage Toutatice 68 ms
    P04 54e160f Requetage GAR 135 ms

==== `P05` - Temps de réponse mesuré lors du requêtage de CouchDB

Cette durée correspond plus précisément au temps total de traitement d'une opération effectuée par la couche technique gérant la connexion avec CouchDB (Ektorp).

Format : `P05 %{idCorrelation} Traitement operation de persistance %{durée} ms`

Exemple :

    P05 1126ccd5 Traitement opération de persistance 120 ms

==== I01 - Réception d'une requête sur l'API

Format : `I01 %{idCorrelation} %{methode} %{ressource}`

Exemples :

    I01 861ab POST /api/catalogue/user1/sync
    I01 4621c87 GET /api/catalogue/user2/favoris

==== W01 - Réponse en erreur (dû à une requête invalide)

Format : `W01 %{idCorrelation} %{codeHTTP} Requete invalide`

Exemples :

    W01 861ab 400 Requête invalide

==== E01 - Réponse en erreur (dû à une erreur du service)

Format : `E01 %{idCorrelation} %{codeHTTP} Erreur serveur`

Exemple :

    E01 861ab 500 Erreur serveur

==== D01 - Requêtage d'un _consumer_

Format : `D01 %{idCorrelation} %{idConsumer} %{methode} %{url}`

Exemple :

    D01 1436ffd Arena GET http://cua-staging.ipanema.education.fr/consumers/arena/api/user1

==== E02 - Réponse d'un _consumer_ en erreur (erreur côté _consumer_)

Format : `E02 %{idCorrelation} %{idConsumer} %{codeHTTP} %{message}`

Exemple :

    E02 1436ffd Arena 500 Server error

==== E03 - Timeout lors du requêtage d'un _consumer_

Format : `E03 %{idCorrelation} %{idConsumer} Timeout après %{durée} ms`

Exemple :

    E03 332fb8 Toutatice Timeout après 2000 ms

==== E04 - Réponse d'un _consumer_ en erreur (dû à une requête invalide)

Format : `E04 %{idCorrelation} %{idConsumer} %{codeHTTP} %{message}`

Exemple :

    E04 332fb8 Toutatice 400 Header X-Token manquant

==== D02 - Changement d'état pour une opération de synchronisation

Format : `D02 %{idCorrelation} %{message}`

Exemples :

    D02 84123 Mise en file d'attente de l'opération de synchronisation
    D02 84123 Démarrage de l'opération de synchronisation
    D02 84123 Opération de synchronisation terminée

==== I02 - Synchronisation réussie

Format : `I02 %{idCorrelation} %{idConsumer} %{nombre} applications synchronisées`

Exemple :

    I02 458fc89 GAR 54 applications synchronisées

==== W04 - Synchronisation échouée

Format : `W04 %{idCorrelation} %{idConsumer} %{message}`

Exemple :

    W04 8743a Toutatice Synchronisation échouée en l'absence de réponse du consumer

==== D03 - Requêtage de CouchDB

Requêtage à travers la couche technique en charge de la gestion de la persistance (Ektorp).

Format : `D03 %{idCorrelation} %{operation} %{message}`

Exemples :

    D03 8743aee CREATE_DATABASE Nouvelle base de données 'bbertrand'
    D03 54ffab5 UPDATE_DOCUMENT Mise-à-jour de l'application 774a698

==== E05 - Erreur lors des échanges avec CouchDB

Format : `E05 %{idCorrelation} %{message}`

Exemple :

    E05 8743aee org.ektorp.DbAccessException: java.net.ConnectException: Connection refused (Connection refused)

=== Métriques exposées

Spring Boot Actuator est utilisé pour exposer des métriques représentatives de l'état de l'application.
Elles sont exposées sous la forme d'un service REST via les ressources suivantes :

* `/actuator/health` : état de santé de l'application
* `/actuator/info` : informations de l'application

TODO : mise en place de la remontée et représentation des informations suivantes, et autres informations utiles :

* Nombre de synchronisations en cours
* Nombre de synchronisations en attente

== Utilisation

Ci-après une description sommaire des ressources et opérations métier exposées par l'application.
Une page de documentation Swagger-UI est exposée par l'application.
Si vous avez lancé le service localement, vous la trouverez http://localhost:8080/swagger-ui.html[en suivant ce lien].

=== Synchronisation

* `GET /api/catalogues/{catalogueId}/sync` : consultation de l'état de la synchronisation
* `POST /api/catalogues/{catalogueId}/sync` : lancement d'une opération de synchronisation (vecteurs d'identité à fournir dans le corps de la requête)

=== Applications

* `GET /api/catalogues/{catalogueId}/applications` : consultation de la liste des applications
* `GET /api/catalogues/{catalogueId}/applications/_ids` : consultation de la liste des identifiants d'application
* `PUT /api/catalogues/{catalogueId}/applications/_ids` : modification de l'ordre des applications (via liste des identifiants)

=== Favoris

* `GET /api/catalogues/{catalogueId}/applications/{appId}/favori` : consultation de l'état favori pour une application
* `PUT /api/catalogues/{catalogueId}/applications/{appId}/favori` : modification de l'état favori pour une application
* `GET /api/catalogues/{catalogueId}/favoris` : consultation de la liste des applications favorites
* `GET /api/catalogues/{catalogueId}/favoris/_ids` : consultation de la liste des identifiants d'application favorites
* `PUT /api/catalogues/{catalogueId}/favoris/_ids` : modification de l'ordre des applications favorites (via liste des identifiants)

== Optimisations et améliorations

En l'état actuel, le code n'est pas optimal, notamment quand on regarde les échanges effectués à l'heure actuelle entre le CUA Hub et CouchDB.
Les modifications suivantes devraient permettre d'améliorer les choses :

=== Limitation du nombre de lectures de l'état de la synchronisation

Au lieu de systématiquement la lire pour chaque modification d'état, il faudrait se contenter de ne récupérer l'état de la synchronisation qu'au lancement de l'opération de synchronisation.
On soumettrait les modifications à CouchDB sur la base de l'objet manipulé dans le CUA Hub, conservé jusqu'à la fin de l'opération de synchronisation.

Pour cela, on devra s'assurer qu'à chaque fois que l'état de la synchronisation est sauvegardée, la propriété `rel` est mise à jour sur la base de la valeur retournée par CouchDB.

Dans les rares cas où on aurait des modifications concurrentes de l'état de la synchronisation, alors il faudra relire l'état de la synchronisation et réappliquer les modifications correspondant au changement d'état avant de retenter une sauvegarde.

On notera que seules la première et la dernière modification dans le cadre de la synchronisation sont importants (l'état des applications exposé étant réputé "instable" tant que l'état de la synchronisation n'est pas `DONE`).

=== Utilisation des opérations "bulk" lors de la synchronisation

La synchronisation, à l'heure actuelle, effectue dans la couche métier le travail de mise-à-jour de manière normalement efficace.
Par contre, la liste des applications envoyées pour mise-à-jour dans la couche persistance n'y est pas traitée de manière groupée mais application par application.

Cela signifie que pour chaque application, on a deux échanges réseau (une lecture puis une écriture) entre CUA Hub et CouchDB.
Avec notre bouchon Toutatice, qui retourne entre 25 et 30 applications, on observe que la synchronisation prend plusieurs secondes (les échanges réseau seuls prenant autour de 100 ms par application).

Or, CouchDB expose des opérations permettant de modifier plusieurs documents en une seule requête.
En les utilisant, on devrait pouvoir réduire de manière notable la durée d'une opération de synchronisation complète.

=== Ne pas systématiquement vérifier l'existence d'un catalogue sur CouchDB

Dans le code actuel, la récupération d'un object `Catalogue` aboutit systématiquement à la vérification de l'existence de celui-ci dans CouchDB.

On devrait pouvoir se passer de cette vérification dans la plupart des cas, car le code tente généralement immédiatement après d'accéder aux documents contenus dans ce catalogue, donc un échange avec CouchDB qui pourrait aboutir à un code 404 retourné si le catalogue n'existe pas.
C'est ce retour en erreur dont on pourrait tenir compte pour informer les clients du CUA Hub de la présence ou non du catalogue.

À noter que l'échange réseau effectué pour vérifier l'existence d'un catalogue est en environnement de test extrêmement rapide (< 10 ms).
Cette optimisation ne semble donc pas prioritaire.

=== Gestion des synchronisations interrompues

Avec le code actuel, si le service est arrêté alors que des synchronisations sont en cours ou en attente, l'état de ces synchronisations est bien conservé dans la base CouchDB.
Par contre, lors du redémarrage du service, les synchronisation en cours ou en attente ne sont pas relancées.
Cela est notamment dû au fait que les informations utiles à la reprise sont réparties dans chacune des bases de données des catalogues.

Une manière de faire serait de laisser les client gérer un "timeout", et redemander une synchronisation au bout d'un certain temps.
Néanmoins, les clients ne savent pas si leur demande de synchronisation a été perdue, ou bien si c'est juste la synchronisation qui prend du temps (à cause d'un problème de charge serveur, par exemple).
Cela devrait fonctionner suffisamment bien dans la plupart des cas avec un timeout suffisamment long (quelques minutes au moins, voire quelques dizaines de minutes).

Une autre façon de faire serait d'informer le client lors d'un `GET sync` de l'état actif ou non de la synchronisation (hors état `DONE`), sur la base d'une information tracée gérée en mémoire par le serveur.
Cette solution a l'avantage d'être simple et efficace mais l'inconvénient de ne plus fonctionner correctement en cas de mise en place de plusieurs instances du service (pour des raison de disponibilité ou de performances).

Pour répondre à ce problème, le mieux serait sans doute de ne pas faire porter la charge de la reprise par le client et de faire évoluer l'architecture du CUA Hub, en séparant le service en charge d'exposer l'API des opérations de synchronisations.
La file d'attente actuellement en place dans le CUA Hub serait implémentée à l'aide de RabbitMQ (ou solution équivalente).
On pourrait alors faire évoluer le nombre d'instance du service API, de la file d'attente pour les synchronisations, du service de synchronisation et du stockage CouchDB de manière indépendante suivant les besoins.
Et on ne pourrait pas perdre de synchronisation en attente ou en cours à moins de mettre à bas toute l'infrastructure.
